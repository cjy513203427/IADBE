/bin/bash /home/jinyao/PycharmProjects/IADBE/test_mvtec_rkde_hazel_nut.sh
(IADBE) jinyao@jinyao-System-Product-Name:~/PycharmProjects/IADBE$ /bin/bash /home/jinyao/PycharmProjects/IADBE/test_mvtec_rkde_hazel_nut.sh
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category screw --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:39:15,782 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:39:15] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:39:15,797 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:39:16,763 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:39:16] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:39:16,764 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:39:16,765 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:39:16,766 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:39:16,869 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:39:16] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:39:16,878 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:39:16,879 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:39:16,880 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:39:16,880 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:39:17,133 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/15/24 12:39:17] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:39:17,176 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[08/15/24 12:39:17] INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:39:17,253 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:39:17,796 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:39:17,798 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:16 • 0:00:00 0.27it/s  2024-08-15 12:39:38,660 - anomalib.callbacks.timer - INFO - Testing took 20.647763967514038 seconds
Throughput (batch_size=32) : 7.74902310253713 FPS
[08/15/24 12:39:38] INFO     Testing took 20.647763967514038 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 7.74902310253713 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.4318508207798004     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:16 • 0:00:00 0.27it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category pill --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:39:44,803 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:39:44] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:39:44,818 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:39:45,784 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:39:45] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:39:45,785 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:39:45,786 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:39:45,787 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:39:45,888 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:39:45] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:39:45,897 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:39:45,898 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:39:45,898 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:39:45,899 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:39:46,151 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/15/24 12:39:46] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:39:46,183 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[08/15/24 12:39:46] INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:39:46,261 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:39:46,771 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:39:46,772 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:19 • 0:00:00 0.27it/s  2024-08-15 12:40:08,563 - anomalib.callbacks.timer - INFO - Testing took 21.578532695770264 seconds
Throughput (batch_size=32) : 7.739173110354008 FPS
[08/15/24 12:40:08] INFO     Testing took 21.578532695770264 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 7.739173110354008 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.41134750843048096    │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:19 • 0:00:00 0.27it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category capsule --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:40:14,477 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:40:14] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:40:14,492 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:40:15,463 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:40:15] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:40:15,464 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:40:15,465 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:40:15,465 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:40:15,567 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:40:15] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:40:15,576 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:40:15,577 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:40:15,578 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:40:15,578 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:40:15,833 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:40:15,876 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:40:15,958 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:40:16,472 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:40:16] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:40:16,473 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:18 • 0:00:00 0.23it/s  2024-08-15 12:40:37,447 - anomalib.callbacks.timer - INFO - Testing took 20.741235733032227 seconds
Throughput (batch_size=32) : 6.364133829778449 FPS
[08/15/24 12:40:37] INFO     Testing took 20.741235733032227 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 6.364133829778449 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.4954128563404083     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:18 • 0:00:00 0.23it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category carpet --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:40:43,209 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:40:43] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:40:43,224 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:40:44,190 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:40:44] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:40:44,191 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:40:44,192 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:40:44,193 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:40:44,294 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:40:44] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:40:44,303 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:40:44,304 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:40:44,305 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:40:44,305 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:40:44,563 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:40:44,608 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:40:44,682 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:40:45,196 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:40:45] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:40:45,197 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:14 • 0:00:00 0.23it/s  2024-08-15 12:41:03,773 - anomalib.callbacks.timer - INFO - Testing took 18.363911151885986 seconds
Throughput (batch_size=32) : 6.371191792004724 FPS
[08/15/24 12:41:03] INFO     Testing took 18.363911151885986 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 6.371191792004724 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5634028911590576     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:14 • 0:00:00 0.23it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category grid --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:41:09,730 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:41:09] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:41:09,745 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:41:10,766 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:41:10] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:41:10,767 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:41:10,768 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:41:10,769 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:41:10,870 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:41:10] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:41:10,879 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:41:10,880 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:41:10,881 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:41:10,881 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:41:11,152 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/15/24 12:41:11] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:41:11,197 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[08/15/24 12:41:11] INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:41:11,269 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:41:11,811 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:41:11,812 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:09 • 0:00:00 0.25it/s  2024-08-15 12:41:24,592 - anomalib.callbacks.timer - INFO - Testing took 12.55404019355774 seconds
Throughput (batch_size=32) : 6.213139260142457 FPS
[08/15/24 12:41:24] INFO     Testing took 12.55404019355774 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 6.213139260142457 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5112781524658203     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:09 • 0:00:00 0.25it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category tile --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:41:30,502 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:41:30] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:41:30,517 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:41:31,497 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:41:31] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:41:31,498 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:41:31,499 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:41:31,500 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:41:31,602 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:41:31] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:41:31,611 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:41:31,612 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:41:31,613 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:41:31,613 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:41:31,867 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:41:31,913 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:41:31,995 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:41:32,501 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:41:32] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:41:32,502 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:15 • 0:00:00 0.21it/s  2024-08-15 12:41:52,846 - anomalib.callbacks.timer - INFO - Testing took 20.102887868881226 seconds
Throughput (batch_size=32) : 5.820059324964604 FPS
[08/15/24 12:41:52] INFO     Testing took 20.102887868881226 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 5.820059324964604 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │     0.51875901222229      │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:15 • 0:00:00 0.21it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category wood --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:41:59,030 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:41:59] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:41:59,045 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:42:00,015 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:42:00] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:42:00,017 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:42:00,018 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:42:00,018 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:42:00,119 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:42:00] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:42:00,128 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:42:00,129 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:42:00,130 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:42:00,131 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:42:00,385 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:42:00,429 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:42:00,508 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:42:01,024 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:42:01] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:42:01,026 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:09 • 0:00:00 0.24it/s  2024-08-15 12:42:14,274 - anomalib.callbacks.timer - INFO - Testing took 13.008401870727539 seconds
Throughput (batch_size=32) : 6.072998111918083 FPS
[08/15/24 12:42:14] INFO     Testing took 13.008401870727539 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 6.072998111918083 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5122807025909424     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:09 • 0:00:00 0.24it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category zipper --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:42:20,082 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:42:20] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:42:20,097 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:42:21,070 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:42:21] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:42:21,072 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:42:21,073 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:42:21,073 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:42:21,175 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:42:21] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:42:21,184 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:42:21,185 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:42:21,186 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:42:21,186 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:42:21,447 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:42:21,493 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:42:21,569 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:42:22,095 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:42:22] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:42:22,096 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:15 • 0:00:00 0.28it/s  2024-08-15 12:42:41,570 - anomalib.callbacks.timer - INFO - Testing took 19.243741989135742 seconds
Throughput (batch_size=32) : 7.846706741612346 FPS
[08/15/24 12:42:41] INFO     Testing took 19.243741989135742 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 7.846706741612346 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.4843750596046448     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:15 • 0:00:00 0.28it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category cable --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:42:47,879 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:42:47] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:42:47,894 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:42:48,871 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:42:48] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:42:48,873 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:42:48,874 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:42:48,874 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:42:48,977 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:42:48] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:42:48,986 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:42:48,986 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:42:48,987 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:42:48,988 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:42:49,244 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/15/24 12:42:49] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:42:49,289 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[08/15/24 12:42:49] INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:42:49,364 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:42:49,886 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:42:49,887 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:18 • 0:00:00 0.23it/s  2024-08-15 12:43:13,711 - anomalib.callbacks.timer - INFO - Testing took 23.585641145706177 seconds
Throughput (batch_size=32) : 6.3598016722690565 FPS
[08/15/24 12:43:13] INFO     Testing took 23.585641145706177 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 6.3598016722690565 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │     0.489130437374115     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:18 • 0:00:00 0.23it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category toothbrush --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:43:19,758 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:43:19] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:43:19,773 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:43:20,744 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:43:20] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:43:20,745 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:43:20,746 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:43:20,746 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:43:20,849 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:43:20] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:43:20,858 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:43:20,859 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:43:20,859 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:43:20,860 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:43:21,121 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/15/24 12:43:21] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:43:21,166 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[08/15/24 12:43:21] INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:43:21,237 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:43:21,767 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:43:21,769 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:05 • 0:00:00 0.24it/s  2024-08-15 12:43:30,373 - anomalib.callbacks.timer - INFO - Testing took 8.38461685180664 seconds
Throughput (batch_size=32) : 5.009173435390816 FPS
[08/15/24 12:43:30] INFO     Testing took 8.38461685180664 seconds                                                                                                                                             timer.py:109
                             Throughput (batch_size=32) : 5.009173435390816 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5111111402511597     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:05 • 0:00:00 0.24it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category transistor --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:43:36,373 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:43:36] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:43:36,388 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:43:37,355 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:43:37] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:43:37,357 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:43:37,358 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:43:37,358 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:43:37,460 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:43:37] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:43:37,469 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:43:37,470 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:43:37,471 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:43:37,472 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:43:37,726 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:43:37,769 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:43:37,838 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:43:38,355 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:43:38] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:43:38,356 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:16 • 0:00:00 0.20it/s  2024-08-15 12:43:57,584 - anomalib.callbacks.timer - INFO - Testing took 18.98652720451355 seconds
Throughput (batch_size=32) : 5.2668926193215375 FPS
[08/15/24 12:43:57] INFO     Testing took 18.98652720451355 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 5.2668926193215375 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │            0.5            │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:16 • 0:00:00 0.20it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category metal_nut --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:44:03,358 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:44:03] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:44:03,373 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:44:04,340 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:44:04] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:44:04,341 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:44:04,342 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:44:04,342 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:44:04,445 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:44:04] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:44:04,453 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:44:04,454 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:44:04,455 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:44:04,456 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:44:04,710 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:44:04,753 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:44:04,826 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:44:05,337 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:44:05] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:44:05,339 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:12 • 0:00:00 0.27it/s  2024-08-15 12:44:20,468 - anomalib.callbacks.timer - INFO - Testing took 14.897422552108765 seconds
Throughput (batch_size=32) : 7.7194561406678694 FPS
[08/15/24 12:44:20] INFO     Testing took 14.897422552108765 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 7.7194561406678694 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │     0.502443790435791     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:12 • 0:00:00 0.27it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category bottle --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:44:26,568 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:44:26] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:44:26,583 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:44:27,553 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:44:27] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:44:27,554 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:44:27,555 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:44:27,556 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:44:27,658 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:44:27] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:44:27,667 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:44:27,668 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:44:27,668 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:44:27,669 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:44:27,922 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:44:27,967 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:44:28,045 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
[08/15/24 12:44:28] INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:44:28,559 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:44:28,560 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:08 • 0:00:00 0.27it/s  2024-08-15 12:44:40,423 - anomalib.callbacks.timer - INFO - Testing took 11.631812572479248 seconds
Throughput (batch_size=32) : 7.135603284768976 FPS
[08/15/24 12:44:40] INFO     Testing took 11.631812572479248 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 7.135603284768976 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │            0.5            │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:08 • 0:00:00 0.27it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category hazelnut --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:44:46,256 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:44:46] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:44:46,271 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:44:47,258 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:44:47] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:44:47,260 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:44:47,261 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:44:47,261 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:44:47,357 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:44:47] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:44:47,366 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:44:47,367 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:44:47,368 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:44:47,369 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:44:47,635 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:44:47,682 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:44:47,758 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:44:48,291 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/15/24 12:44:48] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:44:48,292 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:13 • 0:00:00 0.23it/s  2024-08-15 12:45:05,727 - anomalib.callbacks.timer - INFO - Testing took 17.21365523338318 seconds
Throughput (batch_size=32) : 6.39027554047163 FPS
[08/15/24 12:45:05] INFO     Testing took 17.21365523338318 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 6.39027554047163 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.8499999642372131     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:13 • 0:00:00 0.23it/s
Running command: anomalib test --config ../configs/models/rkde.yaml --data anomalib.data.MVTec --data.category leather --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/latest/weights/lightning/model.ckpt
2024-08-15 12:45:11,542 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/15/24 12:45:11] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-15 12:45:11,557 - anomalib.models.components.base.anomaly_module - INFO - Initializing Rkde model.
                    INFO     Initializing Rkde model.                                                                                                                                                  anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2024-08-15 12:45:12,572 - anomalib.callbacks - INFO - Loading the callbacks
[08/15/24 12:45:12] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-15 12:45:12,573 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Rkde
                    INFO     Overriding gradient_clip_val from None with 0 for Rkde                                                                                                                            engine.py:84
2024-08-15 12:45:12,574 - anomalib.engine.engine - INFO - Overriding max_epochs from None with 1 for Rkde
                    INFO     Overriding max_epochs from None with 1 for Rkde                                                                                                                                   engine.py:84
2024-08-15 12:45:12,575 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Rkde
                    INFO     Overriding num_sanity_val_steps from None with 0 for Rkde                                                                                                                         engine.py:84
2024-08-15 12:45:12,677 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/15/24 12:45:12] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-15 12:45:12,686 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-15 12:45:12,687 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-15 12:45:12,688 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:45:12,688 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-15 12:45:12,953 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-15 12:45:12,996 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-15 12:45:13,071 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
[08/15/24 12:45:13] INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                    rank_zero.py:63
2024-08-15 12:45:13,583 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-15 12:45:13,585 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Rkde/MVTec/hazelnut/v2/weights/lightning/model.ckpt                                     rank_zero.py:63
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(),
RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default),
antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms
from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:14 • 0:00:00 0.23it/s  2024-08-15 12:45:33,114 - anomalib.callbacks.timer - INFO - Testing took 19.28057360649109 seconds
Throughput (batch_size=32) : 6.431343928390884 FPS
[08/15/24 12:45:33] INFO     Testing took 19.28057360649109 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 6.431343928390884 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.2781929075717926     │
│         image_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:14 • 0:00:00 0.23it/s

