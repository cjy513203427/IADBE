/bin/bash /home/jinyao/PycharmProjects/IADBE/train_test_cardboard_cfa.sh
(IADBE) jinyao@jinyao-System-Product-Name:~/PycharmProjects/IADBE$ /bin/bash /home/jinyao/PycharmProjects/IADBE/train_test_cardboard_cflow.sh
Running command: anomalib train --data ../configs/data/custom_dataset_normal_abnormal_cardboard.yaml --model anomalib.models.Cfa
2024-08-02 10:53:07,945 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/02/24 10:53:07] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-02 10:53:07,959 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-02 10:53:08,906 - anomalib.callbacks - INFO - Loading the callbacks
[08/02/24 10:53:08] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-02 10:53:08,908 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-02 10:53:08,908 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-02 10:53:09,001 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/02/24 10:53:09] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-02 10:53:09,010 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-02 10:53:09,011 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-02 10:53:09,011 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-02 10:53:09,012 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-02 10:53:09,013 - anomalib.models.components.base.anomaly_module - WARNING - No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use case. Please override `configure_transforms` in your model.
[08/02/24 10:53:09] WARNING  No implementation of `configure_transforms` was provided in the Lightning model. Using default transforms from the base class. This may not be suitable for your use     anomaly_module.py:235
                             case. Please override `configure_transforms` in your model.
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.
2024-08-02 10:53:09,058 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-02 10:53:09,083 - anomalib.data.base.datamodule - INFO - No normal test images found. Sampling from training set using a split ratio of 0.20
                    INFO     No normal test images found. Sampling from training set using a split ratio of 0.20                                                                                          datamodule.py:177
2024-08-02 10:53:12,141 - anomalib.metrics.f1_score - WARNING - F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead
[08/02/24 10:53:12] WARNING  F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead                                                f1_score.py:33
2024-08-02 10:53:12,143 - anomalib.metrics.f1_score - WARNING - F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead
                    WARNING  F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead                                                f1_score.py:33
2024-08-02 10:53:12,313 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/02/24 10:53:12] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name                  ┃ Type                     ┃ Params ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model                 │ CfaModel                 │ 31.3 M │
│ 1 │ loss                  │ CfaLoss                  │      0 │
│ 2 │ _transform            │ Compose                  │      0 │
│ 3 │ normalization_metrics │ MinMax                   │      0 │
│ 4 │ image_threshold       │ F1AdaptiveThreshold      │      0 │
│ 5 │ pixel_threshold       │ F1AdaptiveThreshold      │      0 │
│ 6 │ image_metrics         │ AnomalibMetricCollection │      0 │
│ 7 │ pixel_metrics         │ AnomalibMetricCollection │      0 │
└───┴───────────────────────┴──────────────────────────┴────────┘
Trainable params: 31.3 M
Non-trainable params: 0
Total params: 31.3 M
Total estimated model params size (MB): 125
  0%|                                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]
 33%|#############################################################3                                                                                                                          | 1/3 [00:01<00:02,  1.10s/it]
 67%|##########################################################################################################################6                                                             | 2/3 [00:01<00:00,  1.84it/s]
100%|########################################################################################################################################################################################| 3/3 [00:01<00:00,  2.65it/s]
100%|########################################################################################################################################################################################| 3/3 [00:01<00:00,  1.99it/s]

Epoch 999/999 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:02 • 0:00:00 1.31it/s pixel_AUROC: 0.877 pixel_F1Score: 0.3512024-08-02 12:10:50,642 - lightning.pytorch.utilities.rank_zero - INFO - `Trainer.fit` stopped: `max_epochs=1000` reached.
[08/02/24 12:10:50] INFO     `Trainer.fit` stopped: `max_epochs=1000` reached.                                                                                                                              rank_zero.py:63
Epoch 999/999 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:02 • 0:00:00 1.31it/s pixel_AUROC: 0.877 pixel_F1Score: 0.3512024-08-02 12:10:51,013 - anomalib.callbacks.timer - INFO - Training took 4658.69 seconds
[08/02/24 12:10:51] INFO     Training took 4658.69 seconds                                                                                                                                                      timer.py:59
Epoch 999/999 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:02 • 0:00:00 1.31it/s pixel_AUROC: 0.877 pixel_F1Score: 0.351
2024-08-02 12:10:51,021 - anomalib.metrics.f1_score - WARNING - F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead
                    WARNING  F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead                                                f1_score.py:33
2024-08-02 12:10:51,023 - anomalib.metrics.f1_score - WARNING - F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead
                    WARNING  F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead                                                f1_score.py:33
2024-08-02 12:10:51,167 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/02/24 12:10:51] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s  2024-08-02 12:10:55,558 - anomalib.callbacks.timer - INFO - Testing took 3.9013495445251465 seconds
Throughput (batch_size=64) : 5.8953958719942 FPS
[08/02/24 12:10:55] INFO     Testing took 3.9013495445251465 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=64) : 5.8953958719942 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.8484848737716675     │
│       image_F1Score       │    0.7777777910232544     │
│        pixel_AUROC        │    0.8617032170295715     │
│       pixel_F1Score       │    0.29311928153038025    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s

