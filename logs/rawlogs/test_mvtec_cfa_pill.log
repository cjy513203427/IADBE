/bin/bash /home/jinyao/PycharmProjects/IADBE/test_mvtec_cfa_pill.sh
(IADBE) jinyao@jinyao-System-Product-Name:~/PycharmProjects/IADBE$ /bin/bash /home/jinyao/PycharmProjects/IADBE/test_mvtec_cfa_pill.sh
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category screw --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:08:14,999 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:08:14] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:08:15,015 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
[08/14/24 11:08:15] INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:08:15,875 - anomalib.callbacks - INFO - Loading the callbacks
                    INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:08:15,876 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:08:15,877 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:08:15,971 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:08:15] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:08:15,980 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:08:15,981 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:08:15,982 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:08:15,983 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:08:16,103 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/14/24 11:08:16] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:08:16,145 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[08/14/24 11:08:16] INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:08:16,228 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:08:16,517 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:08:16,518 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:21 • 0:00:00 0.19it/s  2024-08-14 11:08:47,829 - anomalib.callbacks.timer - INFO - Testing took 31.058794021606445 seconds
Throughput (batch_size=32) : 5.1515200457781445 FPS
[08/14/24 11:08:47] INFO     Testing took 31.058794021606445 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 5.1515200457781445 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5626153349876404     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.9303728342056274     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:21 • 0:00:00 0.19it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category pill --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:08:53,598 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:08:53] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:08:53,615 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:08:54,482 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:08:54] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:08:54,483 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:08:54,484 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:08:54,578 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:08:54] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:08:54,587 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:08:54,588 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:08:54,589 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:08:54,589 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:08:54,709 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:08:54,753 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:08:54,836 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:08:55,113 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/14/24 11:08:55] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:08:55,115 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:24 • 0:00:00 0.21it/s  2024-08-14 11:09:24,386 - anomalib.callbacks.timer - INFO - Testing took 29.027361392974854 seconds
Throughput (batch_size=32) : 5.753192573694178 FPS
[08/14/24 11:09:24] INFO     Testing took 29.027361392974854 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 5.753192573694178 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.9323512315750122     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │     0.978786051273346     │
│         pixel_PRO         │    0.8044094443321228     │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6 0:00:24 • 0:00:00 0.21it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category capsule --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:09:30,118 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:09:30] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:09:30,135 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:09:31,008 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:09:31] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:09:31,010 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:09:31,011 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:09:31,104 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:09:31] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:09:31,113 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:09:31,114 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:09:31,115 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:09:31,116 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:09:31,234 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:09:31,277 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:09:31,356 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:09:31,629 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:09:31,630 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:23 • 0:00:00 0.17it/s  2024-08-14 11:09:59,811 - anomalib.callbacks.timer - INFO - Testing took 27.910985708236694 seconds
Throughput (batch_size=32) : 4.729320611598681 FPS
[08/14/24 11:09:59] INFO     Testing took 27.910985708236694 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 4.729320611598681 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.2983645796775818     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.8619668483734131     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:23 • 0:00:00 0.17it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category carpet --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:10:05,672 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:10:05] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:10:05,689 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:10:06,560 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:10:06] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:10:06,562 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:10:06,562 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:10:06,658 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:10:06] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:10:06,667 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:10:06,667 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:10:06,668 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:10:06,669 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:10:06,787 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:10:06,828 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:10:06,908 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:10:07,170 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/14/24 11:10:07] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:10:07,172 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:17 • 0:00:00 0.17it/s  2024-08-14 11:10:32,101 - anomalib.callbacks.timer - INFO - Testing took 24.64829969406128 seconds
Throughput (batch_size=32) : 4.746777727154535 FPS
[08/14/24 11:10:32] INFO     Testing took 24.64829969406128 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 4.746777727154535 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.5613964796066284     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.8672194480895996     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:17 • 0:00:00 0.17it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category grid --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:10:37,752 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:10:37] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:10:37,769 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:10:38,635 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:10:38] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:10:38,636 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:10:38,637 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:10:38,733 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:10:38] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:10:38,743 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:10:38,744 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:10:38,744 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:10:38,745 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:10:38,864 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:10:38,909 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:10:38,985 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:10:39,259 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/14/24 11:10:39] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:10:39,260 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:11 • 0:00:00 0.18it/s  2024-08-14 11:10:55,279 - anomalib.callbacks.timer - INFO - Testing took 15.747979879379272 seconds
Throughput (batch_size=32) : 4.953016234300299 FPS
[08/14/24 11:10:55] INFO     Testing took 15.747979879379272 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 4.953016234300299 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │            0.5            │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │     0.178100124001503     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:11 • 0:00:00 0.18it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category tile --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:11:01,125 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:11:01] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:11:01,142 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:11:02,011 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:11:02] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:11:02,013 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:11:02,013 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:11:02,107 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:11:02] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:11:02,116 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:11:02,117 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:11:02,118 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:11:02,118 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:11:02,242 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:11:02,285 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:11:02,364 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:11:02,648 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:11:02,649 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:17 • 0:00:00 0.18it/s  2024-08-14 11:11:26,586 - anomalib.callbacks.timer - INFO - Testing took 23.677608966827393 seconds
Throughput (batch_size=32) : 4.941377322512521 FPS
[08/14/24 11:11:26] INFO     Testing took 23.677608966827393 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 4.941377322512521 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.6720778942108154     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.5607105493545532     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:17 • 0:00:00 0.18it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category wood --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:11:32,436 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:11:32] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:11:32,453 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:11:33,324 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:11:33] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:11:33,325 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:11:33,326 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:11:33,420 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:11:33] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:11:33,429 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:11:33,429 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:11:33,430 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:11:33,431 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:11:33,550 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:11:33,576 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:11:33,655 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:11:33,929 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:11:33,930 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:12 • 0:00:00 0.17it/s  2024-08-14 11:11:51,488 - anomalib.callbacks.timer - INFO - Testing took 17.277055740356445 seconds
Throughput (batch_size=32) : 4.572538353017442 FPS
[08/14/24 11:11:51] INFO     Testing took 17.277055740356445 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 4.572538353017442 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.7385964393615723     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.8135310411453247     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:12 • 0:00:00 0.17it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category zipper --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:11:57,196 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:11:57] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:11:57,213 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:11:58,092 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:11:58] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:11:58,093 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:11:58,094 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:11:58,189 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:11:58] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:11:58,198 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:11:58,199 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:11:58,200 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:11:58,200 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:11:58,322 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:11:58,366 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:11:58,447 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:11:58,728 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:11:58,729 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:21 • 0:00:00 0.19it/s  2024-08-14 11:12:27,456 - anomalib.callbacks.timer - INFO - Testing took 28.46394443511963 seconds
Throughput (batch_size=32) : 5.3049569550765385 FPS
[08/14/24 11:12:27] INFO     Testing took 28.46394443511963 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 5.3049569550765385 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │            0.5            │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.5525285601615906     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:21 • 0:00:00 0.19it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category cable --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:12:33,104 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:12:33] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:12:33,121 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:12:33,990 - anomalib.callbacks - INFO - Loading the callbacks
                    INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:12:33,992 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:12:33,992 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:12:34,086 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:12:34] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:12:34,095 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:12:34,096 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:12:34,097 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:12:34,097 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:12:34,221 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/14/24 11:12:34] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:12:34,265 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:12:34,346 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:12:34,624 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:12:34,626 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:23 • 0:00:00 0.17it/s  2024-08-14 11:13:06,226 - anomalib.callbacks.timer - INFO - Testing took 31.318368434906006 seconds
Throughput (batch_size=32) : 4.789521533082705 FPS
[08/14/24 11:13:06] INFO     Testing took 31.318368434906006 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 4.789521533082705 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.4836956560611725     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.5592522621154785     │
│         pixel_PRO         │    0.9998632073402405     │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5/5 0:00:23 • 0:00:00 0.17it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category toothbrush --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:13:11,930 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:13:11] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:13:11,947 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:13:12,840 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:13:12] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:13:12,841 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:13:12,842 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:13:12,935 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:13:12] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:13:12,944 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:13:12,945 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:13:12,945 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:13:12,946 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:13:13,066 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/14/24 11:13:13] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:13:13,110 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[08/14/24 11:13:13] INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:13:13,179 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:13:13,455 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:13:13,456 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:06 • 0:00:00 0.18it/s  2024-08-14 11:13:23,655 - anomalib.callbacks.timer - INFO - Testing took 9.912896394729614 seconds
Throughput (batch_size=32) : 4.23690496980581 FPS
[08/14/24 11:13:23] INFO     Testing took 9.912896394729614 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 4.23690496980581 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.4833333194255829     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.9012629985809326     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2/2 0:00:06 • 0:00:00 0.18it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category transistor --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:13:29,481 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:13:29] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:13:29,498 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:13:30,365 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:13:30] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:13:30,366 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:13:30,367 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:13:30,461 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:13:30] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:13:30,470 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:13:30,471 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:13:30,471 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:13:30,472 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:13:30,595 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:13:30,641 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:13:30,716 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:13:30,993 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:13:30,994 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:17 • 0:00:00 0.17it/s  2024-08-14 11:13:53,051 - anomalib.callbacks.timer - INFO - Testing took 21.788172483444214 seconds
Throughput (batch_size=32) : 4.589646060310253 FPS
[08/14/24 11:13:53] INFO     Testing took 21.788172483444214 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 4.589646060310253 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │            0.5            │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.5101957321166992     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:17 • 0:00:00 0.17it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category metal_nut --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:13:58,622 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:13:58] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:13:58,641 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:13:59,506 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:13:59] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:13:59,507 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:13:59,508 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:13:59,602 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:13:59] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:13:59,611 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:13:59,612 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:13:59,613 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:13:59,614 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:13:59,735 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:13:59,776 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:13:59,854 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:14:00,123 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/14/24 11:14:00] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:14:00,125 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:15 • 0:00:00 0.20it/s  2024-08-14 11:14:21,262 - anomalib.callbacks.timer - INFO - Testing took 20.858615159988403 seconds
Throughput (batch_size=32) : 5.51330944638148 FPS
[08/14/24 11:14:21] INFO     Testing took 20.858615159988403 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 5.51330944638148 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.4469696581363678     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.7526748776435852     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:15 • 0:00:00 0.20it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category bottle --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:14:27,075 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:14:27] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:14:27,091 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:14:27,957 - anomalib.callbacks - INFO - Loading the callbacks
                    INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:14:27,959 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:14:27,959 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:14:28,053 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:14:28] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:14:28,062 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:14:28,063 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:14:28,064 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:14:28,065 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:14:28,184 - anomalib.data.image.mvtec - INFO - Found the dataset.
[08/14/24 11:14:28] INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:14:28,229 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:14:28,304 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:14:28,578 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
                    INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:14:28,579 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:11 • 0:00:00 0.19it/s  2024-08-14 11:14:44,910 - anomalib.callbacks.timer - INFO - Testing took 16.038950443267822 seconds
Throughput (batch_size=32) : 5.174902204080215 FPS
[08/14/24 11:14:44] INFO     Testing took 16.038950443267822 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 5.174902204080215 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │            0.5            │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.22399723529815674    │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3/3 0:00:11 • 0:00:00 0.19it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category hazelnut --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:14:50,642 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:14:50] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:14:50,659 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:14:51,524 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:14:51] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:14:51,525 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:14:51,526 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:14:51,620 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:14:51] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:14:51,629 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:14:51,630 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:14:51,631 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:14:51,631 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:14:51,754 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:14:51,797 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:14:51,878 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:14:52,157 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/14/24 11:14:52] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:14:52,159 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:16 • 0:00:00 0.18it/s  2024-08-14 11:15:14,915 - anomalib.callbacks.timer - INFO - Testing took 22.47471857070923 seconds
Throughput (batch_size=32) : 4.894388316984775 FPS
[08/14/24 11:15:14] INFO     Testing took 22.47471857070923 seconds                                                                                                                                            timer.py:109
                             Throughput (batch_size=32) : 4.894388316984775 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.9296428561210632     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.9621708393096924     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:16 • 0:00:00 0.18it/s
Running command: anomalib test --config ../configs/models/cfa.yaml --data anomalib.data.MVTec --data.category leather --ckpt_path /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/latest/weights/lightning/model.ckpt
2024-08-14 11:15:20,566 - anomalib.utils.config - WARNING - Anomalib currently does not support multi-gpu training. Setting devices to 1.
[08/14/24 11:15:20] WARNING  Anomalib currently does not support multi-gpu training. Setting devices to 1.                                                                                                    config.py:262
2024-08-14 11:15:20,583 - anomalib.models.components.base.anomaly_module - INFO - Initializing Cfa model.
                    INFO     Initializing Cfa model.                                                                                                                                                   anomaly_module.py:42
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'
  torch.has_cuda,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'
  torch.has_cudnn,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'
  torch.has_mps,
/home/jinyao/anaconda3/envs/IADBE/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'
  torch.has_mkldnn,
2024-08-14 11:15:21,453 - anomalib.callbacks - INFO - Loading the callbacks
[08/14/24 11:15:21] INFO     Loading the callbacks                                                                                                                                                           __init__.py:43
2024-08-14 11:15:21,454 - anomalib.engine.engine - INFO - Overriding gradient_clip_val from None with 0 for Cfa
                    INFO     Overriding gradient_clip_val from None with 0 for Cfa                                                                                                                             engine.py:84
2024-08-14 11:15:21,455 - anomalib.engine.engine - INFO - Overriding num_sanity_val_steps from None with 0 for Cfa
                    INFO     Overriding num_sanity_val_steps from None with 0 for Cfa                                                                                                                          engine.py:84
2024-08-14 11:15:21,550 - lightning.pytorch.utilities.rank_zero - INFO - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[08/14/24 11:15:21] INFO     Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default               rank_zero.py:63
                             `ModelSummary` callback.
2024-08-14 11:15:21,559 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
                    INFO     GPU available: True (cuda), used: True                                                                                                                                         rank_zero.py:63
2024-08-14 11:15:21,560 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
                    INFO     TPU available: False, using: 0 TPU cores                                                                                                                                       rank_zero.py:63
2024-08-14 11:15:21,560 - lightning.pytorch.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs
                    INFO     IPU available: False, using: 0 IPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:15:21,561 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
                    INFO     HPU available: False, using: 0 HPUs                                                                                                                                            rank_zero.py:63
2024-08-14 11:15:21,683 - anomalib.data.image.mvtec - INFO - Found the dataset.
                    INFO     Found the dataset.                                                                                                                                                                mvtec.py:412
2024-08-14 11:15:21,727 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
                    INFO     You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' |         rank_zero.py:63
                             'high')` which will trade-off precision for performance. For more details, read
                             https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2024-08-14 11:15:21,807 - lightning.pytorch.utilities.rank_zero - INFO - Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Restoring states from the checkpoint path at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                         rank_zero.py:63
2024-08-14 11:15:22,090 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[08/14/24 11:15:22] INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]                                                                                                                                           cuda.py:58
2024-08-14 11:15:22,092 - lightning.pytorch.utilities.rank_zero - INFO - Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt
                    INFO     Loaded model weights from the checkpoint at /home/jinyao/PycharmProjects/IADBE/results/Cfa/MVTec/pill/v0/weights/lightning/model.ckpt                                          rank_zero.py:63
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:18 • 0:00:00 0.17it/s  2024-08-14 11:15:48,874 - anomalib.callbacks.timer - INFO - Testing took 26.512152671813965 seconds
Throughput (batch_size=32) : 4.6771004050466605 FPS
[08/14/24 11:15:48] INFO     Testing took 26.512152671813965 seconds                                                                                                                                           timer.py:109
                             Throughput (batch_size=32) : 4.6771004050466605 FPS
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│        image_AUROC        │    0.6222826242446899     │
│         image_PRO         │            1.0            │
│        pixel_AUROC        │    0.8325943350791931     │
│         pixel_PRO         │            1.0            │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:00:18 • 0:00:00 0.17it/s

